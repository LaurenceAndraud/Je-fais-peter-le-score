{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df57b309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "from features_functions import compute_features\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4329d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the paths to the files \n",
    "data_path = \"Data/\"\n",
    "\n",
    "# Names of the classes\n",
    "classes_paths = [\"Cars/\", \"Trucks/\"]\n",
    "classes_names = [\"car\", \"truck\"]\n",
    "cars_list = [4,5,7,9,10,15,20,21,23,26,30,38,39,44,46,48,51,52,53,57] # ne pas changer\n",
    "trucks_list = [2,4,10,11,13,20,22,25,27,30,31,32,33,35,36,39,40,45,47,48] # ne pas changer\n",
    "nbr_of_sigs = 20 # Nbr of sigs in each class\n",
    "seq_length = 0.2 # Nbr of second of signal for one sequence\n",
    "nbr_of_obs = int(nbr_of_sigs*10/seq_length) # Each signal is 10 s long\n",
    "\n",
    "# Go to search for the files\n",
    "learning_labels = []\n",
    "for i in range(2*nbr_of_sigs):\n",
    "    if i < nbr_of_sigs:\n",
    "        name = f\"{classes_names[0]}{cars_list[i]}.wav\"\n",
    "        class_path = classes_paths[0]\n",
    "    else:\n",
    "        name = f\"{classes_names[1]}{trucks_list[i - nbr_of_sigs]}.wav\"\n",
    "        class_path = classes_paths[1]\n",
    "\n",
    "    # Read the data and scale them between -1 and 1\n",
    "    fs, data = sio.wavfile.read(data_path + class_path + name)\n",
    "    data = data.astype(float)\n",
    "    data = data/32768\n",
    "\n",
    "    # Cut the data into sequences (we take off the last bits)\n",
    "    data_length = data.shape[0]\n",
    "    nbr_blocks = int((data_length/fs)/seq_length)\n",
    "    seqs = data[:int(nbr_blocks*seq_length*fs)].reshape((nbr_blocks, int(seq_length*fs)))\n",
    "\n",
    "    for k_seq, seq in enumerate(seqs):\n",
    "        # Compute the signal in three domains\n",
    "        sig_sq = seq**2\n",
    "        sig_t = seq / np.sqrt(sig_sq.sum())\n",
    "        sig_f = np.absolute(np.fft.fft(sig_t))\n",
    "        sig_c = np.absolute(np.fft.fft(sig_f))\n",
    "\n",
    "        # Compute the features and store them\n",
    "        features_list = []\n",
    "        N_feat, features_list = compute_features(sig_t, sig_f[:sig_t.shape[0]//2], sig_c[:sig_t.shape[0]//2], fs)\n",
    "        features_vector = np.array(features_list)[np.newaxis,:]\n",
    "\n",
    "        if k_seq == 0 and i == 0:\n",
    "            learning_features = features_vector\n",
    "            learning_labels.append(classes_names[0])\n",
    "        elif i < nbr_of_sigs:\n",
    "            learning_features = np.vstack((learning_features, features_vector))\n",
    "            learning_labels.append(classes_names[0])\n",
    "        else:\n",
    "            learning_features = np.vstack((learning_features, features_vector))\n",
    "            learning_labels.append(classes_names[1])\n",
    "\n",
    "print(learning_features.shape)\n",
    "print(len(learning_labels))\n",
    "\n",
    "# Separate data in train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(learning_features, learning_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the labels\n",
    "labelEncoder = preprocessing.LabelEncoder().fit(y_train)\n",
    "learningLabelsStd = labelEncoder.transform(y_train)\n",
    "testLabelsStd = labelEncoder.transform(y_test)\n",
    "\n",
    "# Learn the model\n",
    "model = svm.SVC(C=10, kernel='linear', class_weight=None, probability=False)\n",
    "scaler = preprocessing.StandardScaler(with_mean=True).fit(X_train)\n",
    "learningFeatures_scaled = scaler.transform(X_train)\n",
    "\n",
    "model.fit(learningFeatures_scaled, learningLabelsStd)\n",
    "\n",
    "# Test the model\n",
    "testFeatures_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Accuracy\n",
    "accuracy = model.score(testFeatures_scaled, testLabelsStd)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5939f79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test GridSearch\n",
    "parameters = {\n",
    "    'C' : [1, 5, 10, 15, 20, 25, 30],\n",
    "    'kernel' : ['rbf', 'linear', 'poly', 'sigmoid']\n",
    "}\n",
    "grid = GridSearchCV(SVC(), parameters, refit=True, verbose=3)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(grid.best_params_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
